<!doctype html>
<meta charset="utf-8">
<meta name="viewport" content="width=1080">
<script src="assets/lib/template.v1.js"></script>
<script type="text/front-matter">
  title: Introduction to optimization algorithms
  description: A bird-eye view of optimization algorithms.
  authors:
    - Fabian Pedregosa: http://fa.bianp.net
  affiliations:
    - UC Berkeley and ETH Zurich
</script>

<!-- OpenGraph Info -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
      TeX: {
        equationNumbers: { autoNumber: "AMS" },
        Macros: {
          RR: "{\\mathbb{R}}",
          argmin: "{\\mathop{\\mathrm{arg\\,min}}}",
          minimize: "{\\mathop{\\mathrm{minimize}}}",
          bold: ["{\\bf #1}",1],
          xx: "{\\boldsymbol x}",
          uu: "{\\boldsymbol u}",
          yy: "{\\boldsymbol y}",
          ss: "{\\boldsymbol s}",
        }
      },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<link rel="stylesheet" type="text/css" href="assets/widgets.css">

<!-- Required -->
<script src="assets/lib/lib.js"></script>
<script src="assets/utils.js"></script>
<script>
  var renderQueue = [];
  function renderMath(elem) {
    // renderMathInElement(
    //     elem,
    //     {
    //         delimiters: [
    //             {left: "$$", right: "$$", display: true},
    //             {left: "$", right: "$", display: false},
    //         ]
    //     }
    // );
  }

  var deleteQueue = [];
  function renderLoading(figure) {
    var loadingScreen = figure.append("svg")
    .style("width", figure.style("width"))
    .style("height", figure.style("height"))
    .style("position","absolute")
    .style("top", "0px")
    .style("left","0px")
    .style("background","white")
    .style("border", "0px dashed #DDD")
    .style("opacity", 1)

    return function(callback) { loadingScreen.remove() };

  }

</script>
<div id="math-cache" style="display: none;">
  <dt-math class="star">\star</dt-math>
  <dt-math class="plus">+</dt-math>
  <dt-math class="minus">-</dt-math>
  <dt-math class="equals">=</dt-math>
  <dt-math class="alpha">\alpha</dt-math>
  <dt-math class="lambda">\lambda</dt-math>
  <dt-math class="beta">\beta</dt-math>
  <dt-math class="r">R</dt-math>
  <dt-math class="alpha-equals">\alpha=</dt-math>
  <dt-math class="beta-equals">\beta=</dt-math>
  <dt-math class="beta-equals-zero">\beta = 0</dt-math>
  <dt-math class="beta-equals-one">\beta=1</dt-math>
  <dt-math class="alpha-equals-one-over-lambda-i">\alpha = 1/\lambda_i</dt-math>
  <dt-math class="model">\text{model}</dt-math>
  <dt-math class="p">0 p_1</dt-math>
  <dt-math class="phat">0 \bar{p}_1</dt-math>
  <dt-math class="two-sqrt-beta">2\sqrt{\beta}</dt-math>
  <dt-math class="lambda-i">\lambda_i</dt-math>
  <dt-math class="lambda-i-equals-zero">\lambda_i = 0</dt-math>
  <dt-math class="alpha-gt-one-over-lambda-i">\alpha > 1/\lambda_i</dt-math>
  <dt-math class="max-sigma-one">\max\{|\sigma_1|,|\sigma_2|\} > 1</dt-math>
  <dt-math class="x-i-k">x_i^k - x_i^*</dt-math>
  <dt-math class="xi-i">\xi_i</dt-math>
  <dt-math class="beta-equals-one-minus">\beta = (1 - \sqrt{\alpha \lambda_i})^2</dt-math>
</div>
<script>
  function MathCache(id) {
    return document.querySelector("#math-cache ." + id).innerHTML;
  }
</script>
<svg style="display: none;">
  <g id="pointerThingy">
    <circle fill="none" stroke="#FF6C00" stroke-linecap="round" cx="0" cy="0" r="14"/>
    <circle fill="#FF6C00" cx="0" cy="0" r="11"/>
    <path id="XMLID_173_" fill="#FFFFFF" d="M-3.2-1.3c0-0.1,0-0.2,0-0.3c0-0.1,0-0.2,0-0.3c-0.6,0-1.2,0-1.8,0c0,0.6,0,1.2,0,1.8
      c0.2,0,0.4,0,0.6,0c0-0.4,0-0.8,0-1.2c0,0,0.1,0,0.1,0c0.3,0,0.5,0,0.8,0C-3.4-1.3-3.3-1.3-3.2-1.3c0,0.2,0,0.4,0,0.6
      c0.2,0,0.4,0,0.6,0c0,0.2,0,0.4,0,0.6c0.2,0,0.4,0,0.6,0c0,0,0,0,0-0.1c0-1.6,0-3.2,0-4.8c0-0.6,0-1.2,0-1.8c0,0,0,0,0.1,0
      c0.3,0,0.7,0,1,0c0.1,0,0.1,0,0.2,0c0-0.2,0-0.4,0-0.6c-0.4,0-0.8,0-1.2,0C-2-7.2-2-7-2-6.8c0,0,0,0-0.1,0c-0.2,0-0.3,0-0.5,0
      c0,0,0,0-0.1,0c0,1.8,0,3.6,0,5.5c-0.2,0-0.3,0-0.4,0C-3.1-1.3-3.2-1.3-3.2-1.3z M1.1-3.7C1-3.8,1-3.8,1.1-3.7C1-4,1-4.1,1-4.3
      c0,0,0,0,0-0.1c-0.4,0-0.8,0-1.2,0c0-0.8,0-1.6,0-2.4c-0.2,0-0.4,0-0.6,0c0,1.8,0,3.6,0,5.5c0.2,0,0.4,0,0.6,0c0-0.8,0-1.6,0-2.4
      c0,0,0.1,0,0.1,0C0.3-3.7,0.6-3.7,1.1-3.7C1-3.7,1-3.7,1.1-3.7C1.1-3.7,1-3.7,1.1-3.7c0,0.8,0,1.6,0,2.3c0,0,0,0.1,0,0.1
      c0.2,0,0.4,0,0.6,0c0-0.6,0-1.2,0-1.8c0.4,0,0.8,0,1.2,0c0,0.8,0,1.6,0,2.4c0.2,0,0.4,0,0.6,0c0-0.6,0-1.2,0-1.8c0.2,0,0.4,0,0.6,0
      c0,0,0,0,0,0.1c0,0.1,0,0.3,0,0.4c0,0,0,0.1,0,0.1c0.2,0,0.4,0,0.5,0c0,0,0.1,0,0.1,0.1c0,0.2,0,0.5,0,0.7c0,1.1,0,2.3,0,3.4
      c0,0,0,0,0,0.1c-0.2,0-0.4,0-0.6,0c0,0,0,0,0,0c0,0.6,0,1.1,0,1.7c0,0,0,0,0,0.1c-0.2,0-0.4,0-0.6,0c0,0.4,0,0.8,0,1.2
      c-1.6,0-3.2,0-4.9,0c0-0.4,0-0.8,0-1.2c-0.2,0-0.4,0-0.6,0C-2,3.8-2,3.4-2,3c-0.2,0-0.4,0-0.6,0c0,0.4,0,0.8,0,1.2
      c0.2,0,0.4,0,0.6,0C-2,4.8-2,5.4-2,6c2,0,4.1,0,6.1,0c0-0.1,0-0.2,0-0.3c0-0.5,0-0.9,0-1.4c0-0.1,0-0.1,0-0.2c0.2,0,0.4,0,0.5,0
      c0.1,0,0.1,0,0.1-0.1c0-0.4,0-0.9,0-1.3c0-0.1,0-0.3,0-0.4c0.1,0,0.2,0,0.3,0c0.1,0,0.2,0,0.3,0c0-1.4,0-2.8,0-4.3
      c-0.2,0-0.4,0-0.6,0c0-0.2,0-0.4,0-0.6c-0.2,0-0.4,0-0.6,0c0-0.2,0-0.4,0-0.6c-0.4,0-0.8,0-1.2,0c0-0.2,0-0.4,0-0.6
      c-0.1,0-0.2,0-0.3,0c-0.4,0-0.9,0-1.3,0C1.2-3.7,1.1-3.7,1.1-3.7z M-3.2,1.8c0,0.4,0,0.8,0,1.2c0.2,0,0.4,0,0.5,0
      c0.1,0,0.1,0,0.1-0.1c0-0.3,0-0.6,0-1c0-0.1,0-0.1,0-0.2C-2.8,1.8-3,1.8-3.2,1.8c0-0.4,0-0.8,0-1.2c-0.2,0-0.4,0-0.6,0
      c0-0.2,0-0.4,0-0.6c-0.2,0-0.4,0-0.6,0c0,0.2,0,0.4,0,0.6c0.2,0,0.4,0,0.6,0c0,0,0,0,0,0.1c0,0.1,0,0.3,0,0.4c0,0.2,0,0.5,0,0.7
      c0,0,0,0.1,0.1,0.1c0.1,0,0.2,0,0.3,0C-3.4,1.8-3.3,1.8-3.2,1.8z"/>
    <path id="XMLID_172_" fill="#FFFFFF" d="M4.1,4.2C4.1,4.2,4.1,4.2,4.1,4.2c0-0.6,0-1.2,0-1.8c0,0,0,0,0,0c0.2,0,0.4,0,0.6,0
      c0,0,0-0.1,0-0.1c0-1.1,0-2.3,0-3.4c0-0.2,0-0.5,0-0.7c0,0,0-0.1-0.1-0.1c-0.2,0-0.4,0-0.5,0c0,0,0-0.1,0-0.1c0-0.1,0-0.3,0-0.4
      c0,0,0-0.1,0-0.1c-0.2,0-0.4,0-0.6,0c0,0.6,0,1.2,0,1.8c-0.2,0-0.4,0-0.6,0c0-0.8,0-1.6,0-2.4c-0.4,0-0.8,0-1.2,0
      c0,0.6,0,1.2,0,1.8c-0.2,0-0.4,0-0.6,0c0,0,0-0.1,0-0.1c0-0.7,0-1.5,0-2.2c0,0,0-0.1,0-0.1l0,0c0.1,0,0.2,0,0.2,0
      c0.4,0,0.9,0,1.3,0c0.1,0,0.2,0,0.3,0c0,0.2,0,0.4,0,0.6c0.4,0,0.8,0,1.2,0c0,0.2,0,0.4,0,0.6c0.2,0,0.4,0,0.6,0c0,0.2,0,0.4,0,0.6
      c0.2,0,0.4,0,0.6,0c0,1.4,0,2.8,0,4.3c-0.1,0-0.2,0-0.3,0c-0.1,0-0.2,0-0.3,0c0,0.1,0,0.3,0,0.4c0,0.4,0,0.9,0,1.3
      c0,0.1,0,0.1-0.1,0.1C4.5,4.2,4.3,4.2,4.1,4.2L4.1,4.2z"/>
    <path id="XMLID_171_" fill="#FFFFFF" d="M4.1,4.2c0,0.1,0,0.1,0,0.2c0,0.5,0,0.9,0,1.4c0,0.1,0,0.2,0,0.3C2.1,6,0,6-2,6
      c0-0.6,0-1.2,0-1.8c-0.2,0-0.4,0-0.6,0c0-0.4,0-0.8,0-1.2C-2.4,3-2.2,3-2,3c0,0.4,0,0.8,0,1.2c0.2,0,0.4,0,0.6,0c0,0.4,0,0.8,0,1.2
      c1.6,0,3.2,0,4.9,0c0-0.4,0-0.8,0-1.2C3.7,4.2,3.9,4.2,4.1,4.2L4.1,4.2z"/>
    <path id="XMLID_170_" fill="#FFFFFF" d="M-2-6.8c0,0.6,0,1.2,0,1.8c0,1.6,0,3.2,0,4.8c0,0,0,0,0,0.1c-0.2,0-0.4,0-0.6,0
      c0-0.2,0-0.4,0-0.6c-0.2,0-0.4,0-0.6,0c0-0.2,0-0.4,0-0.6l0,0c0.1,0,0.1,0,0.2,0c0.1,0,0.3,0,0.4,0c0-1.8,0-3.6,0-5.5
      c0,0,0.1,0,0.1,0C-2.4-6.8-2.2-6.8-2-6.8C-2.1-6.8-2-6.8-2-6.8L-2-6.8z"/>
    <path id="XMLID_169_" fill="#FFFFFF" d="M1.1-3.7C1-3.7,1-3.7,1.1-3.7c-0.4,0-0.8,0-1.2,0c0,0,0,0-0.1,0c0,0.8,0,1.6,0,2.4
      c-0.2,0-0.4,0-0.6,0c0-1.8,0-3.6,0-5.5c0.2,0,0.4,0,0.6,0c0,0.8,0,1.6,0,2.4c0.4,0,0.8,0,1.2,0c0,0,0,0.1,0,0.1C1-4.1,1-4,1.1-3.7
      C1-3.8,1-3.8,1.1-3.7L1.1-3.7z"/>
    <path id="XMLID_168_" fill="#FFFFFF" d="M-3.2,1.8c-0.1,0-0.2,0-0.3,0c-0.1,0-0.2,0-0.3,0c0,0-0.1,0-0.1-0.1c0-0.2,0-0.5,0-0.7
      c0-0.1,0-0.3,0-0.4c0,0,0,0,0-0.1c-0.2,0-0.4,0-0.6,0c0-0.2,0-0.4,0-0.6c0.2,0,0.4,0,0.6,0c0,0.2,0,0.4,0,0.6c0.2,0,0.4,0,0.6,0
      C-3.2,0.9-3.2,1.3-3.2,1.8c0.2,0,0.4,0,0.6,0c0,0.1,0,0.1,0,0.2c0,0.3,0,0.6,0,1C-2.6,3-2.7,3-2.7,3c-0.2,0-0.3,0-0.5,0
      C-3.2,2.6-3.2,2.2-3.2,1.8z"/>
    <path id="XMLID_167_" fill="#FFFFFF" d="M-3.2-1.3c-0.1,0-0.2,0-0.3,0c-0.3,0-0.5,0-0.8,0c0,0,0,0-0.1,0c0,0.4,0,0.8,0,1.2
      c-0.2,0-0.4,0-0.6,0c0-0.6,0-1.2,0-1.8c0.6,0,1.2,0,1.8,0c0,0.1,0,0.2,0,0.3C-3.2-1.5-3.2-1.4-3.2-1.3L-3.2-1.3z"/>
    <path id="XMLID_166_" fill="#FFFFFF" d="M-2-6.8C-2-7-2-7.2-2-7.4c0.4,0,0.8,0,1.2,0c0,0.2,0,0.4,0,0.6c-0.1,0-0.1,0-0.2,0
      C-1.3-6.8-1.6-6.8-2-6.8C-2-6.8-2-6.8-2-6.8L-2-6.8z"/>
  </g>
</svg>

<dt-article class="centered">


  <h1>Introduction to optimization algorithms</h1>
  <dt-byline class="l-page"></dt-byline>


  <h2>Mathematical Optimization</h2>
  <p><i>Mathematical Optimization is the branch of mathematics that aims to solve the problem of finding the elements that maximize or minimize a given real-valued function</i>. Many problems in engineering and machine learning can be cast as mathematical optimization problems, which explains the growing importance of the field. For example, in a spam detection filter we might aim to find the system that minimizes the number of misclassified emails. Similarly, when an engineer designs a pipe, we will seek for the design that minimizes cost while respecting some safety constraints. Both are examples that can be modeled as optimization problems.
  </p>
  <p>The beauty of optimization is that it allows to abstract from the specifics of the particular problem. For example, once we have transformed the spam detection filter and the pipe design the the form of a mathematical optimization problem, we can use the same optimization algorithms to them, abstracting the fact that these are, in origin, very different problems.</p>
  <p>Lets fix some notation. Given a real-valued function $f: \mathcal{X} \to \RR$, and a set $\mathcal{X} \subseteq \RR^{p}$, the general problem of finding the value that minimizes this function is written as follows
  </p>
  <p style="background-color: #D2E4FC; padding: 1px; border-radius: 8px;">\begin{equation}\label{eq:fw_objective}
    \minimize_{\boldsymbol{x} \in \mathcal{X}} f(\boldsymbol{x}) ~,
  \end{equation}</p>
  <p>In this context, $f$ is the <i>objective function</i> (sometimes referred to as loss function, cost function or energy). $\mathcal{X} \subseteq \RR^{p}$ is the <i>domain</i> of the function (also known as constraint set).</p>
  <p>The use of optimization algorithms allows us to abstract from the details of a specific problem and instead view them as instances of a generic problem. This has key advantages: we do not need to develop algorithms for each method separately, instead, the methods developed for a particular algorithm can be applied to any instance of of the same class of problems. </p>




  <h2>The rules of the game</h2>

  <p>Consider the following 2-dimensional optimization problem, in which the objective function $f$ is represented by its level curves:
  </p>
  <figure style = "position:relative; width:984px; height:300px;">
    <div id="banana" style="position:relative; border: 1px solid rgba(0, 0, 0, 0.2);"></div>
  </figure>
  <p>A naive approach is to evaluate the function at a discrete grid and then just select the value that minimize the cost function. However, this approach is very inefficient: the number of function evaluation it requires is exponential in the number of dimensions.</p>
  <p>A more efficient approach instead is to start from an initial guess and iteratively refine the initial guess. The information that to which we have access is the objective function value and its gradient
  </p>
  <figure style = "position:relative; width:984px; height:300px;">
    <div id="banana2" style="position:relative; border: 1px solid rgba(0, 0, 0, 0.2);"></div>
  </figure>
  <p>
  Like a hiker on a foggy day, we seek to reach the bottom of the valley while relying only on local information such as the value and steep (gradient) of the objective function at the current iterate.
  </p>


  
<h2>Knowing your problem</h2>
<p>Not all optimization problems are equal. Knowing your problem enables you
to choose the right tool.</p>
<div class="topic">
<h3>Dimensionality of the problem</h3>
<p>The scale of an optimization problem is pretty much set by the
<em>dimensionality of the problem</em>, i.e. the number of scalar variables
on which the search is performed.</p>
</div>
<div class="section" id="convex-versus-non-convex-optimization">
<h3>Convex versus non-convex optimization</h3>
<table class="docutils" border="1">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><img alt="convex_1d_1" src="https://www.scipy-lectures.org/_images/sphx_glr_plot_convex_001.png"></td>
<td><img alt="convex_1d_2" src="https://www.scipy-lectures.org/_images/sphx_glr_plot_convex_002.png"></td>
</tr>
<tr class="row-even"><td><p class="first"><strong>A convex function</strong>:</p>
<ul class="last simple">
<li><cite>f</cite> is above all its tangents.</li>
<li>equivalently, for two point A, B, f(C) lies below the segment
[f(A), f(B])], if A &lt; C &lt; B</li>
</ul>
</td>
<td><strong>A non-convex function</strong></td>
</tr>
</tbody>
</table>
<p><strong>Optimizing convex functions is typically easier than optimizing non-convex functions.</strong> Convex functions have the nice property that the gradient vanishes only at a global optimum</p>
</div>
<div class="section" id="smooth-and-non-smooth-problems">
<h3>Smooth and non-smooth problems</h3>
<table class="docutils" border="1">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><img alt="smooth_1d_1" src="https://www.scipy-lectures.org/_images/sphx_glr_plot_smooth_001.png"></td>
<td><img alt="smooth_1d_2" src="https://www.scipy-lectures.org/_images/sphx_glr_plot_smooth_002.png"></td>
</tr>
<tr class="row-even"><td><p class="first"><strong>A smooth function</strong>:</p>
<p class="last">The gradient is defined everywhere, and is a continuous function</p>
</td>
<td><strong>A non-smooth function</strong></td>
</tr>
</tbody>
</table>
<p><strong>Optimizing smooth functions is easier</strong>
(true in the context of general function, otherwise
<a class="reference external" href="http://en.wikipedia.org/wiki/Linear_programming">Linear Programming</a>
is an example of methods which deal very efficiently with
piece-wise linear functions).</p>
<p>Smooth functions have the crucial property that at each point admit a quadratic upper bound. I.e., there exists $0 \leq L < \infty$ such that the following inequality is verified for all $\xx, \yy$ in the domain:
\begin{equation}
f(\yy) \leq f(\xx) + \langle \nabla f(\xx), \yy - \xx\rangle + \frac{L}{2}\|\xx - \yy\|^2
\end{equation}
</p>
</div>
<div class="section" id="noisy-versus-exact-cost-functions">
<h3>Noisy versus exact cost functions</h3>
<table class="docutils" border="1">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>Noisy (blue) and non-noisy (green) functions</td>
<td><img alt="noisy" src="https://www.scipy-lectures.org/_images/sphx_glr_plot_noisy_001.png"></td>
</tr>
</tbody>
</table>
<div class="topic">
<p>Many optimization methods rely on gradients of the objective function.
If the gradient function is not given, they are computed numerically,
which induces errors. In such situation, even if the objective
function is not noisy, a gradient-based optimization may be a noisy
optimization.</p>
</div>
</div>
<div class="section" id="constraints">
<h3>Constraints</h3>
<table class="docutils" border="1">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><p class="first">Optimizations under constraints</p>
<p>Here:</p>
<p><img class="math" src="https://www.scipy-lectures.org/_images/math/b270dcff9524408f385d632b77523aed51e9f444.png" alt="-1 < x_1 < 1"></p>
<p class="last"><img class="math" src="https://www.scipy-lectures.org/_images/math/b109b5cb82fcb53f0a1c2d3855cc5340c4598139.png" alt="-1 < x_2 < 1"></p>
</td>
<td><a class="reference external" href="auto_examples/plot_constraints.html"><img alt="constraints" src="https://www.scipy-lectures.org/_images/sphx_glr_plot_constraints_001.png"></a></td>
</tr>
</tbody>
</table>
</div>

<div class="section" id="condition">
<h3>Conditioning</h3>
<p>
  The speed of convergence of most optimization depend on the <i>conditioning</i> of our problem. A well conditioned problem is one in which the curvature is similar among any direction. A badly conditioned problem is one in which the level curves 
</p>
<table class="docutils" border="1">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>
  Well conditioned problem
  <img src="assets/images/levelsets1.png" alt="">
</td>
<td>
  Badly conditioned problem
  <img src="assets/images/levelsets2.png" alt="">
</td>
</tr>
</tbody>
</table>
</div>

<h2>Recommended Readings</h2>
<p>
The recommended reading for this class is the book by Calafiore and El Ghaoui<dt-cite key="calafiore2014optimization"></dt-cite>. Convex Optimization Algorithms by Dimitry Bertsekas<dt-cite key="bertsekas2015convex"></dt-cite> is also a great reference.
</p>
<p>At a more advanced level, the book by Nesterov<dt-cite key="nesterov2013introductory"></dt-cite> is also an excelleng resource.</p>


<script src="assets/lib/contour_plot.js"></script>
<script src="assets/iterates.js"></script>
<script>

// Render Foreground
var iterControl = genIterDiagram(bananaf, [1,1/3], [[-2,2],[2/3 + 0.4,-2/3 + 0.4]], null, false, false, 0)
                  .alpha(0.003)
                  .beta(0)
                  (d3.select("#banana").style("position","relative"))


var iterControl = genIterDiagram(bananaf, [1,1/3], [[-2,2],[2/3 + 0.4,-2/3 + 0.4]], runGradientDescent, true, true, 300)
                  .alpha(0.003)
                  .beta(0)
                  (d3.select("#banana2").style("position","relative"))

// var iterChange = iterControl.control
// var getw0 = iterControl.w0
// 
// var StepRange = d3.scaleLinear().domain([0,100]).range([0,1.00])
// var MomentumRange = d3.scaleLinear().domain([0,100]).range([0,0.98])
// 
// var update = function (i,j) { iterChange(i, 0, getw0()) }
// 
// var slidera = sliderGen([230, 40])
//             .ticks([0,0.02, 0.04, 1.0])
//             .ticktitles( function(d,i) { return ["0", "0.02", "0.04", "1.0"][i]})
//             .change( function (i) {
//               d3.select("#sliderAlpha").selectAll(".figtext").html("Step-size Î± = " + getalpha().toPrecision(2) )
//               iterChange(getalpha(), getbeta(), getw0() )
//             } )
//             .startxval(0.2)
//             .cRadius(7)
//             .shifty(-12)
//             .margins(20,20)  
// var getalpha = slidera( d3.select("#sliderAlpha")).xval
// var getbeta = function() {return 0;}
// var getbeta  = sliderb( d3.select("#sliderBeta")).xval
// 
// iterChange(getalpha(), getbeta(), getw0() )
</script>

</dt-article>

<dt-appendix class="centered">
</dt-appendix> 

<script type="text/bibliography">
@book{calafiore2014optimization,
  title={Optimization models},
  author={Calafiore, Giuseppe C and El Ghaoui, Laurent},
  year={2014},
  publisher={Cambridge university press},
}
@book{nesterov2013introductory,
  title={Introductory lectures on convex optimization: A basic course},
  author={Nesterov, Yurii},
  year={2013},
  publisher={Springer Science \& Business Media}
}
@book{bertsekas2015convex,
  title={Convex optimization algorithms},
  author={Bertsekas, Dimitri P and Scientific, Athena},
  year={2015},
  publisher={Athena Scientific Belmont}
}

</script>

<!-- Figure render queue -->
<script>

// for (var i = 0; i < renderQueue.length; i++) {
//   renderQueue[i](function() {})
//   deleteQueue[i](function() {})
// }
  setTimeout(function() {
    var q = d3.queue(1);

    d3.zip(deleteQueue,renderQueue).forEach(function(fn) {
      q.defer(function(callback) {
        fn[1](callback);
        fn[0](callback);
        renderMath(document.body);
      });
      q.defer(function(callback) {
        setTimeout(function() {
          callback(null);
        }, 50);
      });
    });
    q.await(function(error) {
      if (error) {
        console.error("Render error.", error)
      } else {
        console.log("Render done.")
      }
    });
  }, 50);

// DEBUG
// renderQueue.forEach( function (fn) { fn( function() {}) } )


</script>
